{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a808948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymupdf\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71d791",
   "metadata": {},
   "source": [
    "# All task  related to Job desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7637fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract jobdescription\n",
    "# Job_desc\n",
    "with open (\"job_desc.txt\",'r') as f:\n",
    "    Job_desc = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cecff6",
   "metadata": {},
   "source": [
    "Cleaning Jobdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4a1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning --> to lower case convert regex matching\n",
    "Job_desc = Job_desc.lower()\n",
    "Job_desc = re.sub('[^a-zA-Z]',' ',Job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0be5b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp -->lemmitization and stop word removing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc_jobDesc = nlp(Job_desc)\n",
    "filtered_token = [token.lemma_ for token in doc_jobDesc if not token.is_stop]\n",
    "corpus_jdsc=\" \".join(filtered_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b077ec",
   "metadata": {},
   "source": [
    "# All task related to Resume pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea47585",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(\"Avishek's resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b29fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from the pdf\n",
    "out = open(\"output.txt\",\"wb\")\n",
    "for page in doc:\n",
    "    text = page.get_text().encode(\"utf8\")\n",
    "    out.write(text)\n",
    "    out.write(bytes((12,)))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b19b4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resume_text=\"\"\n",
    "with open(\"output.txt\",\"r\",encoding=\"utf8\") as f:\n",
    "    resume_text = f.read()\n",
    "candidate_email = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9570df7",
   "metadata": {},
   "source": [
    "Cleanig Resume text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8de1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning Resume text\n",
    "resume_text = re.sub('[^a-zA-Z]',' ',resume_text)\n",
    "resume_text = resume_text.strip()\n",
    "resume_text = resume_text.lower()\n",
    "resume_text = re.sub(r\"[0-9]\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"(linkedin|github)\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"link\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"(:|-)\",\"\",resume_text)\n",
    "candidate_email = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", resume_text)\n",
    "resume_text = re.sub(r\"\\S+@\\S+\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"(email|gmail|mail)\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"(contact|mobile|phone)\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"http?s://\\S+\",\"\",resume_text)\n",
    "resume_text = re.sub(r\"www\\.\\S+\",\"\",resume_text)\n",
    "resume_text = re.sub(r'[â€¢*\\-+]', '', resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9eb99ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "doc_resume = nlp(resume_text)\n",
    "token_resume = [token.lemma_ for token in doc_resume if not token.is_stop]\n",
    "corpus_resume = ' '.join(token_resume)\n",
    "corpus_resume = re.sub(' +',' ',corpus_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6e723",
   "metadata": {},
   "source": [
    "# Skill matchig by spacy rule based matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cc88928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ea4b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_csv = pd.read_csv(\"skill_list.csv\") \n",
    "skill_array = np.array(skill_csv['skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7d6afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching skills from skill list and jobdesc\n",
    "nlp_match = spacy.load(\"en_core_web_sm\")\n",
    "doc1 = nlp_match(corpus_jdsc)\n",
    "\n",
    "matcher = Matcher(nlp_match.vocab)\n",
    "\n",
    "# Add each skill as a separate pattern\n",
    "for skill in skill_array:\n",
    "    skill = skill.lower()\n",
    "    pattern = [{\"LOWER\": skill}]\n",
    "    matcher.add(skill, [pattern])  # skill name as unique matcher ID\n",
    "\n",
    "# Run matcher\n",
    "matches = matcher(doc1)\n",
    "\n",
    "# Extract matched skills\n",
    "jobdesc_skill = set()\n",
    "for match_id, start, end in matches:\n",
    "    skill_name = doc[start:end].text\n",
    "    jobdesc_skill.add(skill_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c50ef4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching skill in jobedesc_Skill and resume\n",
    "doc2 = nlp_match(corpus_resume)\n",
    "matcher2 = Matcher(nlp_match.vocab)\n",
    "for skill in jobdesc_skill:\n",
    "    skill = skill.lower()\n",
    "    pattern = [{\"LOWER\":skill}]\n",
    "    matcher2.add(skill,[pattern])\n",
    "matches2 = matcher2(doc2)\n",
    "# Extract matched skills\n",
    "resume_skill = set()\n",
    "for string_id,start,end in matches2:\n",
    "    skill_name = doc2[start:end].text\n",
    "    resume_skill.add(skill_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41941cf1",
   "metadata": {},
   "source": [
    "# Similarty score TF-IDF and sentimeant analysis (VADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a1467b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb65f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37576434]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "vectors = tf_idf.fit_transform([corpus_resume, corpus_jdsc])\n",
    "similarity_score = cosine_similarity(vectors[0],vectors[1])\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4124862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78736887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(corpus_resume) \n",
    "score = (vs['compound']+1)/2\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "827dbdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5978214712880618"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score = 0.8*similarity_score+score*0.3\n",
    "total_score [0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49852e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
